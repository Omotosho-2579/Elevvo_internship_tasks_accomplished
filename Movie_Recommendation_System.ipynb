{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import normalize\n",
        "from scipy import sparse\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "id": "0it9E0dAsiIe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "a_RKOI5XsAbL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "666d69e0-1f21-4333-89d1-4187bdb5b816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. LOAD YOUR DATASET\n",
        "print(\"1. LOADING DATASET...\")"
      ],
      "metadata": {
        "id": "BV6U6mU1sUVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd64987-0403-4606-a21d-6c116e2bf1bd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. LOADING DATASET...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Familiarize yourself with the content of your downloaded dataset zip file\n",
        "import zipfile\n",
        "\n",
        "zip_path = \"/content/archive (11).zip\"\n",
        "\n",
        "# List contents\n",
        "with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "    print(\"Files in zip:\\n\")\n",
        "    for name in z.namelist():\n",
        "        print(name)"
      ],
      "metadata": {
        "id": "7nVQeYz2sYXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93ca4dec-068d-4174-d22b-c0f4a8e2769c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in zip:\n",
            "\n",
            "ml-latest-small/README.txt\n",
            "ml-latest-small/links.csv\n",
            "ml-latest-small/movies.csv\n",
            "ml-latest-small/ratings.csv\n",
            "ml-latest-small/tags.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "\n",
        "zip_path = \"/content/archive (11).zip\"\n",
        "extract_path = \"/content/movie_recommendation\"\n",
        "\n",
        "# How To Create Extraction Folder if not exists\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Unzip the dataset\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"✅ Dataset extracted to: {extract_path}\")\n",
        "\n",
        "\n",
        "for root, dirs, files in os.walk(extract_path):\n",
        "    for name in files[:20]:  # show only first 20 files\n",
        "        print(os.path.join(root, name))\n"
      ],
      "metadata": {
        "id": "vnL5oNO-2Cfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91192311-73d5-4d6e-b960-96e3b66ae8a2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset extracted to: /content/movie_recommendation\n",
            "/content/movie_recommendation/ml-latest-small/tags.csv\n",
            "/content/movie_recommendation/ml-latest-small/README.txt\n",
            "/content/movie_recommendation/ml-latest-small/movies.csv\n",
            "/content/movie_recommendation/ml-latest-small/ratings.csv\n",
            "/content/movie_recommendation/ml-latest-small/links.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4gCyn3sbDV1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = pd.read_csv(\"/content/movie_recommendation/ml-latest-small/ratings.csv\")\n",
        "movies  = pd.read_csv(\"/content/movie_recommendation/ml-latest-small/movies.csv\")\n",
        "links   = pd.read_csv(\"/content/movie_recommendation/ml-latest-small/links.csv\")\n",
        "tags    = pd.read_csv(\"/content/movie_recommendation/ml-latest-small/tags.csv\")\n",
        "\n",
        "print(ratings.shape, movies.shape, links.shape, tags.shape)\n"
      ],
      "metadata": {
        "id": "xhvzLto6Dkbl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae9a313e-8537-4456-fb2a-d508e2707469"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100836, 4) (9742, 3) (9742, 3) (3683, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.head()"
      ],
      "metadata": {
        "id": "s_BMIH9lDnSw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2009977f-cd28-4061-ae63-e5bab869b1c0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating  timestamp\n",
              "0       1        1     4.0  964982703\n",
              "1       1        3     4.0  964981247\n",
              "2       1        6     4.0  964982224\n",
              "3       1       47     5.0  964983815\n",
              "4       1       50     5.0  964982931"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc0febbe-a8c6-4f2e-a28a-9b5c93076e53\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964982931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc0febbe-a8c6-4f2e-a28a-9b5c93076e53')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc0febbe-a8c6-4f2e-a28a-9b5c93076e53 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc0febbe-a8c6-4f2e-a28a-9b5c93076e53');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-844d1733-671e-45b3-9f77-ccc5d375a0c7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-844d1733-671e-45b3-9f77-ccc5d375a0c7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-844d1733-671e-45b3-9f77-ccc5d375a0c7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ratings"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train/Test Split by User & Utility Mappings"
      ],
      "metadata": {
        "id": "OXzIf0gMDmZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Split each user's ratings into train/test; build ID maps and helper functions\n",
        "\n",
        "RATING_THRESHOLD = 4.0      # Ratings >= threshold are considered \"relevant\" for Precision@K\n",
        "TEST_FRACTION = 0.2          # Fraction of each user's ratings held out for test\n",
        "RANDOM_STATE = 42\n",
        "MIN_RATINGS_PER_USER = 5     # Only users with >= this many ratings are evaluated\n",
        "\n",
        "rng = np.random.default_rng(RANDOM_STATE)\n",
        "\n",
        "# Keep only users with sufficient ratings\n",
        "user_counts = ratings['userId'].value_counts()\n",
        "eligible_users = set(user_counts[user_counts >= MIN_RATINGS_PER_USER].index)\n",
        "ratings_eligible = ratings[ratings['userId'].isin(eligible_users)].copy()\n",
        "\n",
        "# Split per user\n",
        "def train_test_split_per_user(df, test_fraction=0.2, seed=42):\n",
        "    rng_local = np.random.default_rng(seed)\n",
        "    train_rows = []\n",
        "    test_rows  = []\n",
        "    for uid, grp in df.groupby('userId'):\n",
        "        idx = grp.index.to_numpy()\n",
        "        n   = len(idx)\n",
        "        if n == 1:\n",
        "            train_rows.extend(idx)\n",
        "            continue\n",
        "        test_size = max(1, int(round(n * test_fraction)))\n",
        "        test_idx = rng_local.choice(idx, size=test_size, replace=False)\n",
        "        train_idx = np.setdiff1d(idx, test_idx, assume_unique=True)\n",
        "        train_rows.extend(train_idx)\n",
        "        test_rows.extend(test_idx)\n",
        "    return df.loc[train_rows].reset_index(drop=True), df.loc[test_rows].reset_index(drop=True)\n",
        "\n",
        "train_ratings, test_ratings = train_test_split_per_user(ratings_eligible, TEST_FRACTION, RANDOM_STATE)\n",
        "\n",
        "# Build ID mappings using the union of users/items that appear in *train* (model fits on train only).\n",
        "unique_users = np.sort(train_ratings['userId'].unique())\n",
        "unique_items = np.sort(train_ratings['movieId'].unique())\n",
        "\n",
        "user2idx = {u:i for i,u in enumerate(unique_users)}\n",
        "idx2user = {i:u for u,i in user2idx.items()}\n",
        "item2idx = {m:i for i,m in enumerate(unique_items)}\n",
        "idx2item = {i:m for m,i in item2idx.items()}\n",
        "\n",
        "n_users = len(unique_users)\n",
        "n_items = len(unique_items)\n",
        "\n",
        "print(f\"Train users/items: {n_users}/{n_items}\")\n",
        "\n",
        "# Build sparse user-item matrix from train\n",
        "def build_user_item_csr(df, user2idx, item2idx, n_users, n_items):\n",
        "    rows = []\n",
        "    cols = []\n",
        "    data = []\n",
        "    for r in df.itertuples(index=False):\n",
        "        if (r.userId in user2idx) and (r.movieId in item2idx):\n",
        "            rows.append(user2idx[r.userId])\n",
        "            cols.append(item2idx[r.movieId])\n",
        "            data.append(r.rating)\n",
        "    mat = sparse.coo_matrix((data, (rows, cols)), shape=(n_users, n_items))\n",
        "    return mat.tocsr()\n",
        "\n",
        "train_csr = build_user_item_csr(train_ratings, user2idx, item2idx, n_users, n_items)\n",
        "\n",
        "# Helper: get a user's seen items in train\n",
        "def items_seen_in_train(user_csr_row):\n",
        "    return set(user_csr_row.indices.tolist())\n",
        "\n",
        "# Helper: movieId -> title\n",
        "title_map = dict(zip(movies['movieId'], movies['title']))\n"
      ],
      "metadata": {
        "id": "l2QBSDs9FPAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe50a0c-3e30-4c08-b84f-2d9607984861"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train users/items: 610/8977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "User-Based CF: Similarity, Prediction, Recommendation"
      ],
      "metadata": {
        "id": "OaUkeUJIFeml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: User-based collaborative filtering with cosine similarity\n",
        "\n",
        "# Optionally mean-center users (helps quality)\n",
        "user_means = np.zeros(n_users)\n",
        "train_csr_centered = train_csr.astype(float).copy()\n",
        "for u in range(n_users):\n",
        "    row = train_csr[u]\n",
        "    if row.nnz > 0:\n",
        "        mean_u = row.data.mean()\n",
        "        user_means[u] = mean_u\n",
        "        train_csr_centered[u, row.indices] = row.data - mean_u\n",
        "\n",
        "# Compute user-user cosine similarity on centered ratings\n",
        "# Normalize each user's vector first (safer for cosine on sparse)\n",
        "train_csr_centered_norm = normalize(train_csr_centered, norm='l2', axis=1, copy=True)\n",
        "user_sim = cosine_similarity(train_csr_centered_norm, dense_output=False)  # sparse result possible\n",
        "\n",
        "def predict_user_based_scores(user_idx, topn_neighbors=25):\n",
        "    \"\"\"\n",
        "    Predict scores for all items for a given user using top-N most similar neighbors.\n",
        "    Returns a 1D numpy array of length n_items with predicted ratings (filled only for unseen items).\n",
        "    \"\"\"\n",
        "    # Similarities for this user\n",
        "    sim_row = user_sim[user_idx].toarray().ravel() if sparse.issparse(user_sim) else user_sim[user_idx]\n",
        "    sim_row[user_idx] = 0.0  # ignore self\n",
        "\n",
        "    # Top-N neighbors\n",
        "    if topn_neighbors is not None and topn_neighbors > 0:\n",
        "        nn_idx = np.argpartition(-sim_row, topn_neighbors)[:topn_neighbors]\n",
        "        sims = sim_row[nn_idx]\n",
        "        neighbor_matrix = train_csr_centered[nn_idx]  # centered ratings\n",
        "    else:\n",
        "        nn_idx = np.where(sim_row > 0)[0]\n",
        "        sims = sim_row[nn_idx]\n",
        "        neighbor_matrix = train_csr_centered[nn_idx]\n",
        "\n",
        "    # Weighted sum of neighbors' centered ratings\n",
        "    if len(nn_idx) == 0 or np.all(sims == 0):\n",
        "        # fallback to user mean if no neighbors\n",
        "        pred = np.full(n_items, user_means[user_idx])\n",
        "        return pred\n",
        "\n",
        "    weights = sims.reshape(-1, 1)  # (neighbors, 1)\n",
        "    # neighbor_matrix is (neighbors, n_items); do weighted sum\n",
        "    num = weights.T.dot(neighbor_matrix.toarray()).ravel()  # (n_items,)\n",
        "    den = np.abs(sims).sum() + 1e-8\n",
        "\n",
        "    centered_pred = num / den\n",
        "    pred = centered_pred + user_means[user_idx]\n",
        "    return pred\n",
        "\n",
        "def recommend_user_based(user_id, k=10, topn_neighbors=25):\n",
        "    if user_id not in user2idx:\n",
        "        raise ValueError(\"User not found in training set.\")\n",
        "    uid = user2idx[user_id]\n",
        "    preds = predict_user_based_scores(uid, topn_neighbors=topn_neighbors)\n",
        "    seen = items_seen_in_train(train_csr[uid])\n",
        "    # Exclude seen items\n",
        "    mask = np.ones(n_items, dtype=bool)\n",
        "    if len(seen) > 0:\n",
        "        mask[list(seen)] = False\n",
        "    preds_unseen = np.where(mask, preds, -np.inf)\n",
        "    topk_idx = np.argpartition(-preds_unseen, k)[:k]\n",
        "    topk_idx = topk_idx[np.argsort(-preds_unseen[topk_idx])]\n",
        "\n",
        "    recs = []\n",
        "    for ii in topk_idx:\n",
        "        movie_id = idx2item[ii]\n",
        "        recs.append((movie_id, title_map.get(movie_id, str(movie_id)), preds_unseen[ii]))\n",
        "    return recs\n",
        "\n",
        "print(\"User-based CF ready.\")\n"
      ],
      "metadata": {
        "id": "uma3CqJrGI46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fed711c-8f2b-48da-bfb8-2ba53315c231"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User-based CF ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision@K Evaluation (User-Based CF)"
      ],
      "metadata": {
        "id": "XlBYEh1VGKm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Evaluate Precision@K for User-Based CF\n",
        "\n",
        "def build_user_test_relevant(test_df, threshold=RATING_THRESHOLD):\n",
        "    \"\"\"\n",
        "    Returns: dict[userId] -> set(movieId) that are relevant in test (rating >= threshold).\n",
        "    Only consider items that exist in training's item universe (so we can recommend them).\n",
        "    \"\"\"\n",
        "    relevant = defaultdict(set)\n",
        "    for r in test_df.itertuples(index=False):\n",
        "        if (r.userId in user2idx) and (r.movieId in item2idx):\n",
        "            if r.rating >= threshold:\n",
        "                relevant[r.userId].add(r.movieId)\n",
        "    return relevant\n",
        "\n",
        "user_test_rel = build_user_test_relevant(test_ratings, RATING_THRESHOLD)\n",
        "\n",
        "def precision_at_k_usercf(k=10, topn_neighbors=25, max_users=None):\n",
        "    users_to_eval = [u for u in unique_users if len(user_test_rel.get(u, set())) > 0]\n",
        "    if max_users is not None:\n",
        "        users_to_eval = users_to_eval[:max_users]\n",
        "\n",
        "    precisions = []\n",
        "    for u in tqdm(users_to_eval, desc=f\"Evaluating UserCF P@{k}\"):\n",
        "        recs = recommend_user_based(u, k=k, topn_neighbors=topn_neighbors)\n",
        "        rec_items = {mid for (mid, _, _) in recs}\n",
        "        hits = len(rec_items & user_test_rel[u])\n",
        "        precisions.append(hits / k)\n",
        "    return float(np.mean(precisions)) if len(precisions) > 0 else np.nan\n",
        "\n",
        "P_at_10_user = precision_at_k_usercf(k=10, topn_neighbors=25)\n",
        "print(f\"User-Based CF Precision@10: {P_at_10_user:.4f}\")\n"
      ],
      "metadata": {
        "id": "Q5e6fTdhG9xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4888b9fe-94ce-4afb-97fb-f365057528b3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating UserCF P@10: 100%|██████████| 602/602 [00:00<00:00, 1316.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User-Based CF Precision@10: 0.1477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Item-Based CF: Similarity, Prediction, Recommendation & Evaluation"
      ],
      "metadata": {
        "id": "gC0OYa6bHXg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Item-based collaborative filtering with cosine similarity\n",
        "\n",
        "# Build item-centered matrix\n",
        "item_means = np.zeros(n_items)\n",
        "train_csr_T = train_csr.transpose().tocsr()  # (n_items, n_users)\n",
        "train_item_centered = train_csr_T.astype(float).copy()\n",
        "for i in range(n_items):\n",
        "    row = train_csr_T[i]\n",
        "    if row.nnz > 0:\n",
        "        mean_i = row.data.mean()\n",
        "        item_means[i] = mean_i\n",
        "        train_item_centered[i, row.indices] = row.data - mean_i\n",
        "\n",
        "# Normalize rows for cosine\n",
        "train_item_centered_norm = normalize(train_item_centered, norm='l2', axis=1, copy=True)\n",
        "item_sim = cosine_similarity(train_item_centered_norm, dense_output=False)  # (n_items, n_items)\n",
        "\n",
        "def predict_item_based_for_user(user_idx, topn_neighbors=50):\n",
        "    \"\"\"\n",
        "    For the given user, predict scores for all items using item-item similarity and the user's known ratings.\n",
        "    \"\"\"\n",
        "    user_row = train_csr[user_idx]  # (1, n_items)\n",
        "    rated_items = user_row.indices\n",
        "    rated_vals  = user_row.data\n",
        "\n",
        "    if len(rated_items) == 0:\n",
        "        # No history; fallback to global item means\n",
        "        return item_means.copy()\n",
        "\n",
        "    # Build a weighted sum of similarities * (user rating - item mean) + item mean\n",
        "    preds = np.zeros(n_items, dtype=float)\n",
        "    denom = np.zeros(n_items, dtype=float)\n",
        "\n",
        "    for idx, r_ui in zip(rated_items, rated_vals):\n",
        "        # Similarities of current rated item to all others\n",
        "        sim_row = item_sim[idx].toarray().ravel() if sparse.issparse(item_sim) else item_sim[idx]\n",
        "        sim_row[idx] = 0.0  # exclude self\n",
        "        if topn_neighbors is not None and topn_neighbors > 0:\n",
        "            nn = np.argpartition(-sim_row, topn_neighbors)[:topn_neighbors]\n",
        "            s  = sim_row[nn]\n",
        "            preds[nn] += s * (r_ui - item_means[idx])\n",
        "            denom[nn] += np.abs(s)\n",
        "        else:\n",
        "            preds += sim_row * (r_ui - item_means[idx])\n",
        "            denom += np.abs(sim_row)\n",
        "\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        centered = np.divide(preds, denom, out=np.zeros_like(preds), where=denom>0)\n",
        "    final_pred = centered + item_means\n",
        "    return final_pred\n",
        "\n",
        "def recommend_item_based(user_id, k=10, topn_neighbors=50):\n",
        "    if user_id not in user2idx:\n",
        "        raise ValueError(\"User not found in training set.\")\n",
        "    uid = user2idx[user_id]\n",
        "    preds = predict_item_based_for_user(uid, topn_neighbors=topn_neighbors)\n",
        "    seen = items_seen_in_train(train_csr[uid])\n",
        "    mask = np.ones(n_items, dtype=bool)\n",
        "    if len(seen) > 0:\n",
        "        mask[list(seen)] = False\n",
        "    preds_unseen = np.where(mask, preds, -np.inf)\n",
        "    topk_idx = np.argpartition(-preds_unseen, k)[:k]\n",
        "    topk_idx = topk_idx[np.argsort(-preds_unseen[topk_idx])]\n",
        "\n",
        "    recs = []\n",
        "    for ii in topk_idx:\n",
        "        movie_id = idx2item[ii]\n",
        "        recs.append((movie_id, title_map.get(movie_id, str(movie_id)), preds_unseen[ii]))\n",
        "    return recs\n",
        "\n",
        "def precision_at_k_itemcf(k=10, topn_neighbors=50, max_users=None):\n",
        "    users_to_eval = [u for u in unique_users if len(user_test_rel.get(u, set())) > 0]\n",
        "    if max_users is not None:\n",
        "        users_to_eval = users_to_eval[:max_users]\n",
        "\n",
        "    precisions = []\n",
        "    for u in tqdm(users_to_eval, desc=f\"Evaluating ItemCF P@{k}\"):\n",
        "        recs = recommend_item_based(u, k=k, topn_neighbors=topn_neighbors)\n",
        "        rec_items = {mid for (mid, _, _) in recs}\n",
        "        hits = len(rec_items & user_test_rel[u])\n",
        "        precisions.append(hits / k)\n",
        "    return float(np.mean(precisions)) if len(precisions) > 0 else np.nan\n",
        "\n",
        "P_at_10_item = precision_at_k_itemcf(k=10, topn_neighbors=50)\n",
        "print(f\"Item-Based CF Precision@10: {P_at_10_item:.4f}\")\n"
      ],
      "metadata": {
        "id": "98LomNqAHZBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d51c79b7-c62d-4b94-d03a-0eadd7d2c026"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ItemCF P@10: 100%|██████████| 602/602 [00:13<00:00, 44.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Item-Based CF Precision@10: 0.0035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVD implementation using scikit-learn instead of Surprise & Precision@K"
      ],
      "metadata": {
        "id": "OsvZ7mFNG-i1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Alternative SVD implementation using scikit-learn instead of Surprise\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Create user-item matrix from training data\n",
        "def create_user_item_matrix_svd(train_ratings, user2idx_svd, item2idx_svd):\n",
        "    \"\"\"Create sparse user-item rating matrix for SVD\"\"\"\n",
        "    n_users = len(user2idx_svd)\n",
        "    n_items = len(item2idx_svd)\n",
        "\n",
        "    # Map to indices\n",
        "    user_indices = train_ratings['userId'].map(user2idx_svd)\n",
        "    item_indices = train_ratings['movieId'].map(item2idx_svd)\n",
        "    ratings = train_ratings['rating'].values\n",
        "\n",
        "    # Create sparse matrix\n",
        "    user_item_matrix = csr_matrix(\n",
        "        (ratings, (user_indices, item_indices)),\n",
        "        shape=(n_users, n_items)\n",
        "    )\n",
        "\n",
        "    return user_item_matrix\n",
        "\n",
        "# Create separate mappings for SVD (to avoid conflicts with your existing mappings)\n",
        "unique_users_svd = train_ratings['userId'].unique()\n",
        "unique_items_svd = train_ratings['movieId'].unique()\n",
        "user2idx_svd = {user: idx for idx, user in enumerate(unique_users_svd)}\n",
        "item2idx_svd = {item: idx for idx, item in enumerate(unique_items_svd)}\n",
        "idx2user_svd = {idx: user for user, idx in user2idx_svd.items()}\n",
        "idx2item_svd = {idx: item for item, idx in item2idx_svd.items()}\n",
        "\n",
        "print(f\"Creating user-item matrix with {len(unique_users_svd)} users and {len(unique_items_svd)} items\")\n",
        "\n",
        "# Create the user-item matrix\n",
        "user_item_matrix = create_user_item_matrix_svd(train_ratings, user2idx_svd, item2idx_svd)\n",
        "\n",
        "# Apply SVD\n",
        "print(\"Fitting SVD model...\")\n",
        "n_components = 50  # Same as n_factors in Surprise\n",
        "svd_model = TruncatedSVD(n_components=n_components, random_state=RANDOM_STATE)\n",
        "\n",
        "# Fit SVD on the user-item matrix\n",
        "user_factors = svd_model.fit_transform(user_item_matrix)\n",
        "item_factors = svd_model.components_.T\n",
        "\n",
        "# Get global mean rating for bias\n",
        "global_mean = train_ratings['rating'].mean()\n",
        "\n",
        "# Calculate user and item biases\n",
        "user_means = np.array([\n",
        "    train_ratings[train_ratings['userId'] == idx2user_svd[i]]['rating'].mean()\n",
        "    if i < len(idx2user_svd) else global_mean\n",
        "    for i in range(len(unique_users_svd))\n",
        "])\n",
        "user_biases = user_means - global_mean\n",
        "\n",
        "item_means = np.array([\n",
        "    train_ratings[train_ratings['movieId'] == idx2item_svd[i]]['rating'].mean()\n",
        "    if i < len(idx2item_svd) else global_mean\n",
        "    for i in range(len(unique_items_svd))\n",
        "])\n",
        "item_biases = item_means - global_mean\n",
        "\n",
        "def predict_rating(user_id, item_id):\n",
        "    \"\"\"Predict rating for user-item pair\"\"\"\n",
        "    if user_id not in user2idx_svd or item_id not in item2idx_svd:\n",
        "        return global_mean\n",
        "\n",
        "    user_idx = user2idx_svd[user_id]\n",
        "    item_idx = item2idx_svd[item_id]\n",
        "\n",
        "    # Biased SVD prediction: global_mean + user_bias + item_bias + dot_product\n",
        "    prediction = (global_mean +\n",
        "                 user_biases[user_idx] +\n",
        "                 item_biases[item_idx] +\n",
        "                 np.dot(user_factors[user_idx], item_factors[item_idx]))\n",
        "\n",
        "    # Clip to rating scale\n",
        "    min_rating = train_ratings['rating'].min()\n",
        "    max_rating = train_ratings['rating'].max()\n",
        "    return np.clip(prediction, min_rating, max_rating)\n",
        "\n",
        "# Build train user-item sets for filtering\n",
        "train_user_items = defaultdict(set)\n",
        "for r in train_ratings.itertuples(index=False):\n",
        "    train_user_items[r.userId].add(r.movieId)\n",
        "\n",
        "all_train_items_svd = set(unique_items_svd)\n",
        "\n",
        "def svd_topk_for_user(user_id, k=10):\n",
        "    \"\"\"Recommend top-K items not seen in train for this user using SVD predictions.\"\"\"\n",
        "    if user_id not in user2idx_svd:\n",
        "        return []\n",
        "\n",
        "    # Get unseen items\n",
        "    unseen = list(all_train_items_svd - train_user_items[user_id])\n",
        "\n",
        "    # Predict ratings for unseen items\n",
        "    predictions = []\n",
        "    for item_id in unseen:\n",
        "        pred_rating = predict_rating(user_id, item_id)\n",
        "        predictions.append((item_id, pred_rating))\n",
        "\n",
        "    # Sort by predicted rating (descending)\n",
        "    predictions.sort(key=lambda x: -x[1])\n",
        "\n",
        "    # Return top-K with movie titles\n",
        "    topk = predictions[:k]\n",
        "    return [(mid, title_map.get(mid, str(mid)), rating) for (mid, rating) in topk]\n",
        "\n",
        "def precision_at_k_svd(k=10, max_users=None):\n",
        "    \"\"\"Calculate Precision@K for SVD model\"\"\"\n",
        "    users_to_eval = [u for u in unique_users_svd if len(user_test_rel.get(u, set())) > 0]\n",
        "    if max_users is not None:\n",
        "        users_to_eval = users_to_eval[:max_users]\n",
        "\n",
        "    precisions = []\n",
        "    for u in tqdm(users_to_eval, desc=f\"Evaluating SVD P@{k}\"):\n",
        "        recs = svd_topk_for_user(u, k=k)\n",
        "        rec_items = {mid for (mid, _, _) in recs}\n",
        "        hits = len(rec_items & user_test_rel[u])\n",
        "        precisions.append(hits / k)\n",
        "\n",
        "    return float(np.mean(precisions)) if len(precisions) > 0 else np.nan\n",
        "\n",
        "# Calculate Precision@10\n",
        "print(\"Calculating Precision@10...\")\n",
        "P_at_10_svd = precision_at_k_svd(k=10)\n",
        "print(f\"SVD (MF) Precision@10: {P_at_10_svd:.4f}\")\n",
        "\n",
        "# Show some sample recommendations\n",
        "print(\"\\nSample recommendations for first user:\")\n",
        "sample_user = unique_users_svd[0]\n",
        "sample_recs = svd_topk_for_user(sample_user, k=5)\n",
        "for i, (movie_id, title, pred_rating) in enumerate(sample_recs, 1):\n",
        "    print(f\"{i}. {title} (Predicted rating: {pred_rating:.2f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCt4O9sGd84H",
        "outputId": "596766fd-2cb6-493f-d572-5897fa726d05"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating user-item matrix with 610 users and 8977 items\n",
            "Fitting SVD model...\n",
            "Calculating Precision@10...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating SVD P@10: 100%|██████████| 602/602 [33:32<00:00,  3.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVD (MF) Precision@10: 0.0654\n",
            "\n",
            "Sample recommendations for first user:\n",
            "1. Casino (1995) (Predicted rating: 5.00)\n",
            "2. Persuasion (1995) (Predicted rating: 5.00)\n",
            "3. City of Lost Children, The (Cité des enfants perdus, La) (1995) (Predicted rating: 5.00)\n",
            "4. Twelve Monkeys (a.k.a. 12 Monkeys) (1995) (Predicted rating: 5.00)\n",
            "5. The Brain (1969) (Predicted rating: 5.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo: Show Top Recommendations for a Sample User"
      ],
      "metadata": {
        "id": "gI8vuMnqH0tQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Demo recommendations for one sample user across methods\n",
        "\n",
        "# Pick a user with at least one relevant test item and who exists in train\n",
        "candidate_users = [u for u in unique_users if len(user_test_rel.get(u, set())) > 0]\n",
        "demo_user = int(candidate_users[0]) if len(candidate_users) else int(unique_users[0])\n",
        "\n",
        "print(f\"Demo user: {demo_user}\")\n",
        "\n",
        "print(\"\\nUser-Based CF top-10:\")\n",
        "for mid, title, score in recommend_user_based(demo_user, k=10, topn_neighbors=25):\n",
        "    print(f\"{title}  (pred: {score:.3f})\")\n",
        "\n",
        "print(\"\\nItem-Based CF top-10:\")\n",
        "for mid, title, score in recommend_item_based(demo_user, k=10, topn_neighbors=50):\n",
        "    print(f\"{title}  (pred: {score:.3f})\")\n",
        "\n",
        "print(\"\\nSVD (MF) top-10:\")\n",
        "for mid, title, score in svd_topk_for_user(demo_user, k=10):\n",
        "    print(f\"{title}  (pred: {score:.3f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyOmx3b6nUA8",
        "outputId": "43838bb7-5f79-4fe2-8fc5-cfd987dfddb7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Demo user: 1\n",
            "\n",
            "User-Based CF top-10:\n",
            "Star Wars: Episode IV - A New Hope (1977)  (pred: 5.026)\n",
            "Forrest Gump (1994)  (pred: 4.897)\n",
            "Shawshank Redemption, The (1994)  (pred: 4.894)\n",
            "Pulp Fiction (1994)  (pred: 4.866)\n",
            "Blade Runner (1982)  (pred: 4.826)\n",
            "Godfather, The (1972)  (pred: 4.813)\n",
            "One Flew Over the Cuckoo's Nest (1975)  (pred: 4.803)\n",
            "Fight Club (1999)  (pred: 4.734)\n",
            "Reservoir Dogs (1992)  (pred: 4.715)\n",
            "Casablanca (1942)  (pred: 4.695)\n",
            "\n",
            "Item-Based CF top-10:\n",
            "Final Fantasy VII: Advent Children (2004)  (pred: 7.800)\n",
            "Pacific Rim: Uprising (2018)  (pred: 7.583)\n",
            "Pirates of Silicon Valley (1999)  (pred: 7.500)\n",
            "Kinky Boots (2005)  (pred: 7.446)\n",
            "Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)  (pred: 7.375)\n",
            "Friday the 13th Part VI: Jason Lives (1986)  (pred: 7.361)\n",
            "Seed of Chucky (Child's Play 5) (2004)  (pred: 7.342)\n",
            "Smokey and the Bandit II (1980)  (pred: 7.322)\n",
            "Professional, The (Le professionnel) (1981)  (pred: 7.300)\n",
            "Birthday Girl (2001)  (pred: 7.300)\n",
            "\n",
            "SVD (MF) top-10:\n",
            "Casino (1995)  (pred: 5.000)\n",
            "Persuasion (1995)  (pred: 5.000)\n",
            "City of Lost Children, The (Cité des enfants perdus, La) (1995)  (pred: 5.000)\n",
            "Twelve Monkeys (a.k.a. 12 Monkeys) (1995)  (pred: 5.000)\n",
            "The Brain (1969)  (pred: 5.000)\n",
            "Babe (1995)  (pred: 5.000)\n",
            "Cry, the Beloved Country (1995)  (pred: 5.000)\n",
            "Lamerica (1994)  (pred: 5.000)\n",
            "Indian in the Cupboard, The (1995)  (pred: 5.000)\n",
            "Friday (1995)  (pred: 5.000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kN3215ZvnVov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "THE END!!!"
      ],
      "metadata": {
        "id": "x_wws1Gz1Eek"
      }
    }
  ]
}